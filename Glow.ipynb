{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "n_bins = 2 ** 8\n",
    "\n",
    "train_dataset = dsets.MNIST(\n",
    "    root='./MNIST/', \n",
    "    train=True, \n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        lambda x: x + torch.zeros_like(x).uniform_(0, 1. / n_bins)\n",
    "    ]),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActNorm(nn.Module):\n",
    "    def __init__(self, h, w, c):\n",
    "        super().__init__()\n",
    "        self.shape = (h, w, c)\n",
    "        self.initialized = False\n",
    "        self.weights = nn.Parameter(torch.Tensor(c))\n",
    "        self.bias = nn.Parameter(torch.Tensor(c))\n",
    "        \n",
    "    def forward(self, inp, logdet):\n",
    "        if not self.initialized:\n",
    "            c = self.shape[-1]\n",
    "            self.weights.data = 1/inp.transpose(0, 1).contiguous().view(c, -1).std(1)\n",
    "            self.bias.data = -(inp * self.weights[..., None, None]).transpose(0, 1).contiguous().view(c, -1).mean(1)\n",
    "            self.initialized = True\n",
    "        \n",
    "        return inp * self.weights[..., None, None] + self.bias[..., None, None], logdet + self.shape[0] * self.shape[1] * torch.sum(torch.abs(self.weights))\n",
    "    \n",
    "    def reverse(self, out):\n",
    "        return (out - self.bias[..., None, None]) / self.weights[..., None, None]\n",
    "\n",
    "class InvertibleConv(nn.Module):\n",
    "    def __init__(self, h, w, c):\n",
    "        super().__init__()\n",
    "        self.shape = (h, w, c)\n",
    "        self.weight = nn.Parameter(torch.from_numpy(np.linalg.qr(np.random.randn(c, c))[0]).float())\n",
    "                                    \n",
    "    def forward(self, inp, logdet):\n",
    "        return torch.einsum(\"abcd,eb->aecd\", (inp, self.weight)), logdet + self.shape[0] * self.shape[1] * torch.log(torch.abs(torch.det(self.weight)))\n",
    "    \n",
    "    def reverse(self, out):\n",
    "        return torch.einsum(\"abcd,eb->aecd\", (out, torch.inverse(self.weight)))\n",
    "\n",
    "class AffineCoupling(nn.Module):\n",
    "    def __init__(self, h, w, c):\n",
    "        super().__init__()\n",
    "        self.NN = nn.Sequential(\n",
    "            nn.Conv2d(c//2, c//2, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(c//2, c, 3, padding=1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, inp, logdet):        \n",
    "        x_a, x_b = torch.chunk(inp, 2, dim=1)\n",
    "        log_s, t = torch.chunk(self.NN(x_b), 2, dim=1)\n",
    "        s = torch.exp(log_s)\n",
    "        y_a = s * x_a + t\n",
    "        return torch.cat([y_a, x_b], dim = 1), logdet + torch.sum(torch.log(torch.abs(s)))\n",
    "    \n",
    "    def reverse(self, out):\n",
    "        y_a, y_b = torch.chunk(out, 2, dim=1)\n",
    "        log_s, t = torch.chunk(self.NN(y_b), 2, dim=1)\n",
    "        s = torch.exp(log_s)\n",
    "        x_a = (y_a - t) / s\n",
    "        return torch.cat([x_a, y_b], dim = 1)\n",
    "    \n",
    "class Flow(nn.Module):\n",
    "    def __init__(self, K, h, w, c):\n",
    "        super().__init__()\n",
    "        self.k = K\n",
    "        self.actnorms = nn.ModuleList(ActNorm(h, w, c) for i in range(K))\n",
    "        self.invconvs = nn.ModuleList(InvertibleConv(h, w, c) for i in range(K))\n",
    "        self.couplings = nn.ModuleList(AffineCoupling(h, w, c) for i in range(K))\n",
    "        \n",
    "    def forward(self, inp, logdet, z):        \n",
    "        for i in range(self.k):\n",
    "            inp, logdet = self.actnorms[i](inp, logdet)\n",
    "            inp, logdet = self.invconvs[i](inp, logdet)\n",
    "            inp, logdet = self.couplings[i](inp, logdet)\n",
    "        \n",
    "        return inp, logdet, z\n",
    "    \n",
    "    def reverse(self, inp, z):\n",
    "        for i in range(self.k)[::-1]:\n",
    "            inp = self.couplings[i].reverse(inp)\n",
    "            inp = self.invconvs[i].reverse(inp)\n",
    "            inp = self.actnorms[i].reverse(inp)\n",
    "\n",
    "        return inp, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_unshuffle(input_, block_size=2):\n",
    "    b, c, h, w = input_.shape\n",
    "\n",
    "    assert h % block_size == 0 and w % block_size == 0,\\\n",
    "        f\"Shape must be divisible by block_size, got {input_.shape}\"\n",
    "\n",
    "    oc = c * block_size * block_size;\n",
    "    oh = h // block_size;\n",
    "    ow = w // block_size;\n",
    "\n",
    "    input_reshaped = input_.view(b, c, oh, block_size, ow, block_size)\n",
    "    return input_reshaped.permute(0, 1, 3, 5, 2, 4).reshape(b, oc, oh, ow)\n",
    "    \n",
    "class Squeeze(nn.Module):\n",
    "    def __init__(self, block_size=2):\n",
    "        super().__init__()\n",
    "        self.block_size = block_size \n",
    "\n",
    "    def forward(self, input_, logdet, z):\n",
    "        return pixel_unshuffle(input_, self.block_size), logdet, z\n",
    "    \n",
    "    def reverse(self, input_, z):\n",
    "        return F.pixel_shuffle(input_, self.block_size), z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Split(nn.Module):\n",
    "    def forward(self, input_, logdet, z):\n",
    "        out, zi = torch.chunk(input_, 2, 1)\n",
    "\n",
    "        return out, logdet, z + [zi]\n",
    "    \n",
    "    def reverse(self, input_, z):\n",
    "        out = torch.cat([input_, z[-1]], 1)\n",
    "        \n",
    "        return out, z[:-1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class Split(nn.Module):\n",
    "    def forward(self, input_, logdet, z):\n",
    "        zi, out = torch.chunk(input_, 2, 1)\n",
    "\n",
    "        return out, logdet, z + [zi]\n",
    "    \n",
    "    def reverse(self, input_, z):\n",
    "        out = torch.cat([z[-1], input_], 1)\n",
    "        \n",
    "        return out, z[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogLikelihood(nn.Module): \n",
    "    def __init__(self, size):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.norm = torch.distributions.MultivariateNormal(torch.zeros(size).to(device), torch.eye(size).to(device))\n",
    "\n",
    "    def forward(self, input_, logdet, z):\n",
    "        batch = input_.shape[0]\n",
    "        comb_z = torch.cat([z_.contiguous().view(batch, -1) for z_ in z + [input_]], 1)\n",
    "\n",
    "        return None, (logdet + torch.sum(self.norm.log_prob(comb_z))) / batch, z + [input_]\n",
    "    \n",
    "    def reverse(self, input_, z):\n",
    "        return z[-1], z[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlowModel(nn.Module):\n",
    "    def __init__(self, h, w, c, K, L):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        for i in range(1, L):\n",
    "            self.layers.append(Squeeze())\n",
    "            self.layers.append(Flow(K, h//(2**i), w//(2**i), c*2**(i+1)))\n",
    "            self.layers.append(Split())\n",
    "\n",
    "        self.layers.append(Squeeze())\n",
    "        self.layers.append(Flow(K, h//(2**L), w//(2**L), c*2**(L+1)))\n",
    "        self.layers.append(LogLikelihood(h*w*c))\n",
    "        \n",
    "    def forward(self, input_, logdet, z):\n",
    "        for layer in self.layers:\n",
    "            input_, logdet, z = layer(input_, logdet, z)\n",
    "\n",
    "        return input_, logdet, z\n",
    "    \n",
    "    def reverse(self, input_, z):\n",
    "        for layer in self.layers[::-1]:\n",
    "            input_, z = layer.reverse(input_, z)\n",
    "\n",
    "        return input_, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def train_epoch(model, optimizer, batchsize=32):\n",
    "    loss_log, acc_log = [], []\n",
    "    model.train()\n",
    "    batch_iter =tqdm(train_loader)\n",
    "    for x_batch, _ in batch_iter:\n",
    "        data = x_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out, logdet, z = model(data, 0, [])\n",
    "        \n",
    "        loss = -logdet# + np.log(n_bins) * np.prod(x_batch.shape[1:])\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_value_(model.parameters(), 5)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 100)\n",
    "        optimizer.step()\n",
    "        loss = loss.item()\n",
    "        batch_iter.set_postfix(loss=loss)\n",
    "        loss_log.append(loss)\n",
    "    return loss_log\n",
    "\n",
    "def plot_history(train_history, title='loss'):\n",
    "    plt.figure()\n",
    "    plt.title('{}'.format(title))\n",
    "    plt.plot(train_history, label='train', zorder=1)\n",
    "    \n",
    "    plt.xlabel('train steps')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def train(model, opt, n_epochs):\n",
    "    train_log, train_acc_log = [], []\n",
    "    val_log, val_acc_log = [], []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = train_epoch(model, opt, batchsize=batch_size)\n",
    "        train_log.extend(train_loss)\n",
    "\n",
    "        steps = train_dataset.train_labels.shape[0] / batch_size\n",
    "\n",
    "        clear_output()\n",
    "        plot_history(train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e299c16e4b40c789859c86a5a51bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=59), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-879e8c6d3940>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlowModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-f747e3d2c6bb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, opt, n_epochs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mtrain_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-f747e3d2c6bb>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, batchsize)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbatch_iter\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python3.6/site-packages/tqdm/_tqdm_notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python3.6/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python3.6/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python3.6/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_pil_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'img should be PIL Image. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Got inappropriate size arg: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = GlowModel(32, 32, 1, 28, 2).to(device)\n",
    "train(model, optim.Adam(model.parameters()), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_dataset[1][0]\n",
    "out, logdet, z = model.forward(img[None, ...].to(device), 0, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.reverse(None, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0].numpy() - res[0].detach().cpu().numpy()[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
